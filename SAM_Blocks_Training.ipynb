{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b383c7c",
   "metadata": {},
   "source": [
    "# ü§ñ S.A.M Blocks AI Training - Google Colab\n",
    "## Train YOLOv8 Block Detection Model\n",
    "\n",
    "**Dataset Location:** `/content/drive/MyDrive/block_dataset`  \n",
    "**Training Time:** 15-30 minutes with GPU  \n",
    "**Goal:** Train AI to detect and count blocks in images\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° IMPORTANT: Enable GPU First!\n",
    "1. Click **Runtime** ‚Üí **Change runtime type**\n",
    "2. Select **Hardware accelerator: GPU**\n",
    "3. Click **Save**\n",
    "\n",
    "Then run all cells in order (Shift + Enter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fe3e03",
   "metadata": {},
   "source": [
    "## Step 1: Mount Google Drive üìÅ\n",
    "Connect to your Google Drive to access the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0cae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"‚úÖ Google Drive mounted successfully!\")\n",
    "print(\"üìÅ Your dataset is at: /content/drive/MyDrive/block_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc0a6df",
   "metadata": {},
   "source": [
    "## Step 2: Check GPU ‚ö°\n",
    "Verify that GPU is enabled (should show NVIDIA Tesla T4 or similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb2f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3787e4",
   "metadata": {},
   "source": [
    "## Step 3: Install YOLOv8 üì¶\n",
    "Install Ultralytics library for training (takes ~2 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics -q\n",
    "\n",
    "# Verify installation\n",
    "import ultralytics\n",
    "print(f\"‚úÖ Ultralytics installed: version {ultralytics.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d5381",
   "metadata": {},
   "source": [
    "## Step 4: Verify Dataset Structure üìä\n",
    "Check what's inside your block_dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09548d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Your dataset location\n",
    "dataset_path = Path('/content/drive/MyDrive/block_dataset')\n",
    "\n",
    "print(f\"üìÅ Dataset location: {dataset_path}\")\n",
    "print(f\"‚úÖ Exists: {dataset_path.exists()}\\n\")\n",
    "\n",
    "if dataset_path.exists():\n",
    "    print(\"üìÇ Contents:\")\n",
    "    for item in sorted(dataset_path.iterdir()):\n",
    "        if item.is_dir():\n",
    "            file_count = len(list(item.iterdir()))\n",
    "            print(f\"  üìÅ {item.name}/ ({file_count} files)\")\n",
    "        else:\n",
    "            print(f\"  üìÑ {item.name}\")\n",
    "    \n",
    "    # Check for images and labels\n",
    "    images_path = dataset_path / 'images'\n",
    "    labels_path = dataset_path / 'labels'\n",
    "    \n",
    "    if images_path.exists():\n",
    "        images = list(images_path.glob('*.[jJ][pP]*[gG]')) + list(images_path.glob('*.[pP][nN][gG]'))\n",
    "        print(f\"\\nüì∏ Total images: {len(images)}\")\n",
    "    \n",
    "    if labels_path.exists():\n",
    "        labels = list(labels_path.glob('*.txt'))\n",
    "        print(f\"üè∑Ô∏è  Total labels: {len(labels)}\")\n",
    "        \n",
    "        # Find matched pairs\n",
    "        if images_path.exists():\n",
    "            image_stems = {img.stem for img in images}\n",
    "            label_stems = {lbl.stem for lbl in labels}\n",
    "            matched = image_stems & label_stems\n",
    "            print(f\"‚úÖ Matched (labeled images): {len(matched)}\")\n",
    "            print(f\"‚ö†Ô∏è  Unlabeled images: {len(image_stems - label_stems)}\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset not found! Check the path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a316908",
   "metadata": {},
   "source": [
    "## Step 5: Copy Dataset to Colab Storage üöÄ\n",
    "Copy from Google Drive to Colab's local storage for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93970efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Copy entire dataset to Colab's fast local storage\n",
    "source = Path('/content/drive/MyDrive/block_dataset')\n",
    "destination = Path('/content/block_dataset')\n",
    "\n",
    "if destination.exists():\n",
    "    shutil.rmtree(destination)\n",
    "\n",
    "print(\"üì¶ Copying dataset to Colab storage...\")\n",
    "shutil.copytree(source, destination)\n",
    "print(f\"‚úÖ Copied to {destination}\")\n",
    "\n",
    "# Verify\n",
    "images_count = len(list((destination / 'images').glob('*')))\n",
    "labels_count = len(list((destination / 'labels').glob('*.txt')))\n",
    "print(f\"üì∏ Images: {images_count}\")\n",
    "print(f\"üè∑Ô∏è  Labels: {labels_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd792958",
   "metadata": {},
   "source": [
    "## Step 6: Split Train/Validation Data üìä\n",
    "Create 80% train / 20% validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcee53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "dataset_path = Path('/content/block_dataset')\n",
    "images_path = dataset_path / 'images'\n",
    "labels_path = dataset_path / 'labels'\n",
    "\n",
    "# Create train/val directories\n",
    "train_images = dataset_path / 'train' / 'images'\n",
    "train_labels = dataset_path / 'train' / 'labels'\n",
    "val_images = dataset_path / 'val' / 'images'\n",
    "val_labels = dataset_path / 'val' / 'labels'\n",
    "\n",
    "for p in [train_images, train_labels, val_images, val_labels]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Get all labeled images (images with corresponding .txt labels)\n",
    "image_files = list(images_path.glob('*.[jJ][pP]*[gG]')) + list(images_path.glob('*.[pP][nN][gG]'))\n",
    "labeled_images = []\n",
    "\n",
    "for img in image_files:\n",
    "    label_file = labels_path / f\"{img.stem}.txt\"\n",
    "    if label_file.exists():\n",
    "        labeled_images.append(img)\n",
    "\n",
    "print(f\"üìä Found {len(labeled_images)} labeled images\")\n",
    "\n",
    "# Shuffle and split (80% train, 20% validation)\n",
    "random.seed(42)  # For reproducibility\n",
    "random.shuffle(labeled_images)\n",
    "\n",
    "split_idx = int(len(labeled_images) * 0.8)\n",
    "train_imgs = labeled_images[:split_idx]\n",
    "val_imgs = labeled_images[split_idx:]\n",
    "\n",
    "print(f\"üìà Train: {len(train_imgs)} images\")\n",
    "print(f\"üìâ Validation: {len(val_imgs)} images\")\n",
    "\n",
    "# Copy files to train/val directories\n",
    "for img in train_imgs:\n",
    "    shutil.copy(img, train_images / img.name)\n",
    "    label = labels_path / f\"{img.stem}.txt\"\n",
    "    shutil.copy(label, train_labels / f\"{img.stem}.txt\")\n",
    "\n",
    "for img in val_imgs:\n",
    "    shutil.copy(img, val_images / img.name)\n",
    "    label = labels_path / f\"{img.stem}.txt\"\n",
    "    shutil.copy(label, val_labels / f\"{img.stem}.txt\")\n",
    "\n",
    "print(\"‚úÖ Dataset split complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fc91dd",
   "metadata": {},
   "source": [
    "## Step 7: Create data.yaml Configuration üìù\n",
    "YOLO needs this config file to find training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e9ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml for YOLO training\n",
    "data_yaml_content = f\"\"\"# S.A.M Blocks Dataset Configuration\n",
    "path: {dataset_path}\n",
    "train: train/images\n",
    "val: val/images\n",
    "\n",
    "names:\n",
    "  0: block\n",
    "\n",
    "nc: 1\n",
    "\"\"\"\n",
    "\n",
    "data_yaml_path = dataset_path / 'data.yaml'\n",
    "with open(data_yaml_path, 'w') as f:\n",
    "    f.write(data_yaml_content)\n",
    "\n",
    "print(f\"‚úÖ Created {data_yaml_path}\\n\")\n",
    "print(\"Contents:\")\n",
    "print(data_yaml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce8cc87",
   "metadata": {},
   "source": [
    "## Step 8: START TRAINING! üöÄüî•\n",
    "Train YOLOv8 model (15-30 minutes with GPU)\n",
    "\n",
    "**Watch the progress below:**\n",
    "- Epochs: 50 training cycles\n",
    "- Lower loss values = better learning\n",
    "- Training saves checkpoints every 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Create directory to save results to Google Drive\n",
    "save_dir = '/content/drive/MyDrive/sam_blocks_training_results'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Load pretrained YOLOv8 Nano segmentation model\n",
    "print(\"üì¶ Loading YOLOv8 Nano model...\")\n",
    "model = YOLO('yolov8n-seg.pt')\n",
    "\n",
    "print(\"\\nüöÄ Starting training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=str(dataset_path / 'data.yaml'),\n",
    "    epochs=50,              # Number of training cycles\n",
    "    imgsz=640,              # Image size (640x640)\n",
    "    batch=8,                # Batch size (reduce to 4 if out-of-memory)\n",
    "    patience=10,            # Stop early if no improvement for 10 epochs\n",
    "    save=True,              # Save checkpoints\n",
    "    project=save_dir,       # Save to Google Drive\n",
    "    name='sam_blocks_v1',   # Experiment name\n",
    "    exist_ok=True,          # Overwrite if exists\n",
    "    pretrained=True,        # Use pretrained weights\n",
    "    optimizer='Adam',       # Adam optimizer\n",
    "    verbose=True,           # Show detailed progress\n",
    "    seed=42,                # Random seed\n",
    "    deterministic=True,     # Reproducible training\n",
    "    single_cls=True,        # Single class (blocks only)\n",
    "    plots=True,             # Generate training plots\n",
    "    save_period=10,         # Save checkpoint every 10 epochs\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüéâ TRAINING COMPLETE!\")\n",
    "print(f\"üìÅ Results saved to: {save_dir}/sam_blocks_v1\")\n",
    "print(f\"üèÜ Best model: {save_dir}/sam_blocks_v1/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6e578e",
   "metadata": {},
   "source": [
    "## Step 9: View Training Results üìä\n",
    "Look at training curves and example detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab64ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "results_dir = f\"{save_dir}/sam_blocks_v1\"\n",
    "\n",
    "print(\"üìä TRAINING RESULTS\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "conf_matrix = f\"{results_dir}/confusion_matrix.png\"\n",
    "if os.path.exists(conf_matrix):\n",
    "    print(\"\\n1Ô∏è‚É£ Confusion Matrix:\")\n",
    "    display(Image(filename=conf_matrix, width=600))\n",
    "\n",
    "# 2. Training Curves (loss, metrics over epochs)\n",
    "results_img = f\"{results_dir}/results.png\"\n",
    "if os.path.exists(results_img):\n",
    "    print(\"\\n2Ô∏è‚É£ Training Curves (Loss & Metrics):\")\n",
    "    display(Image(filename=results_img, width=900))\n",
    "\n",
    "# 3. Validation Predictions\n",
    "val_batch0 = f\"{results_dir}/val_batch0_pred.jpg\"\n",
    "if os.path.exists(val_batch0):\n",
    "    print(\"\\n3Ô∏è‚É£ Example Detections on Validation Images:\")\n",
    "    display(Image(filename=val_batch0, width=900))\n",
    "\n",
    "# 4. F1 Curve\n",
    "f1_curve = f\"{results_dir}/F1_curve.png\"\n",
    "if os.path.exists(f1_curve):\n",
    "    print(\"\\n4Ô∏è‚É£ F1 Score Curve:\")\n",
    "    display(Image(filename=f1_curve, width=600))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f1f7d0",
   "metadata": {},
   "source": [
    "## Step 10: Calculate Model Metrics üìà\n",
    "See how accurate your model is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1912c2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "best_model_path = f\"{save_dir}/sam_blocks_v1/weights/best.pt\"\n",
    "trained_model = YOLO(best_model_path)\n",
    "\n",
    "# Run validation to get metrics\n",
    "print(\"üìä Calculating metrics on validation set...\\n\")\n",
    "metrics = trained_model.val()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Box detection metrics\n",
    "print(f\"\\nüì¶ Bounding Box Detection:\")\n",
    "print(f\"  mAP50 (IoU=0.50):     {metrics.box.map50:.3f}\")\n",
    "print(f\"  mAP50-95:             {metrics.box.map:.3f}\")\n",
    "print(f\"  Precision:            {metrics.box.mp:.3f}\")\n",
    "print(f\"  Recall:               {metrics.box.mr:.3f}\")\n",
    "\n",
    "# Segmentation metrics (if available)\n",
    "if hasattr(metrics, 'seg'):\n",
    "    print(f\"\\nüé≠ Segmentation Masks:\")\n",
    "    print(f\"  mAP50 (IoU=0.50):     {metrics.seg.map50:.3f}\")\n",
    "    print(f\"  mAP50-95:             {metrics.seg.map:.3f}\")\n",
    "    print(f\"  Precision:            {metrics.seg.mp:.3f}\")\n",
    "    print(f\"  Recall:               {metrics.seg.mr:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"\\nüí° What these mean:\")\n",
    "print(\"  ‚Ä¢ mAP50 > 0.5  = Decent model\")\n",
    "print(\"  ‚Ä¢ mAP50 > 0.7  = Good model\")\n",
    "print(\"  ‚Ä¢ mAP50 > 0.9  = Excellent model\")\n",
    "print(\"\\n  ‚Ä¢ Precision = % of detections that are actually blocks\")\n",
    "print(\"  ‚Ä¢ Recall    = % of actual blocks that were detected\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee10336a",
   "metadata": {},
   "source": [
    "## Step 11: Test on Sample Image üñºÔ∏è\n",
    "See your model detect blocks in real-time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50941203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get a validation image\n",
    "test_image = list(val_images.glob('*'))[0]\n",
    "print(f\"üñºÔ∏è  Testing on: {test_image.name}\\n\")\n",
    "\n",
    "# Run inference\n",
    "results = trained_model(test_image)\n",
    "\n",
    "# Display result with detections drawn\n",
    "result = results[0]\n",
    "result_image = result.plot()  # Draw boxes and masks\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.imshow(result_image)\n",
    "plt.axis('off')\n",
    "plt.title(f\"Detection Result: {test_image.name}\", fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detection details\n",
    "print(\"=\" * 60)\n",
    "print(f\"‚úÖ Detected {len(result.boxes)} block(s)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, box in enumerate(result.boxes):\n",
    "    conf = box.conf[0].item()\n",
    "    cls = int(box.cls[0].item())\n",
    "    print(f\"  Block {i+1}: {conf:.1%} confidence\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd254987",
   "metadata": {},
   "source": [
    "## Step 12: Save Final Model üíæ\n",
    "Copy the trained model to an easy-to-find location in Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02323fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Copy best model to Drive root for easy download\n",
    "final_model_src = f\"{save_dir}/sam_blocks_v1/weights/best.pt\"\n",
    "final_model_dest = '/content/drive/MyDrive/block_detector_TRAINED.pt'\n",
    "\n",
    "shutil.copy(final_model_src, final_model_dest)\n",
    "\n",
    "# Get file size\n",
    "file_size_mb = os.path.getsize(final_model_dest) / (1024 * 1024)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üéâ MODEL SAVED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüì¶ Model location: block_detector_TRAINED.pt\")\n",
    "print(f\"üìä File size: {file_size_mb:.1f} MB\")\n",
    "print(f\"\\nüì• To download:\")\n",
    "print(\"  1. Go to https://drive.google.com/\")\n",
    "print(\"  2. Find 'block_detector_TRAINED.pt' in My Drive\")\n",
    "print(\"  3. Right-click ‚Üí Download\")\n",
    "print(\"  4. Save to your computer\")\n",
    "print(\"\\nüìÇ Full results folder: sam_blocks_training_results/sam_blocks_v1/\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n‚úÖ ALL DONE! Your AI model is ready to use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbf9027",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì What You Just Did\n",
    "\n",
    "Congratulations! You just:\n",
    "- ‚úÖ Trained a deep learning model from scratch\n",
    "- ‚úÖ Used transfer learning (started with pretrained YOLOv8)\n",
    "- ‚úÖ Split data scientifically (80/20 train/val)\n",
    "- ‚úÖ Evaluated model performance with metrics\n",
    "- ‚úÖ Created a production-ready AI model\n",
    "\n",
    "## üìä Understanding Your Results\n",
    "\n",
    "**If mAP50 is:**\n",
    "- **0.3 - 0.5**: Basic detection, needs more training data\n",
    "- **0.5 - 0.7**: Good! Model works well for most cases\n",
    "- **0.7 - 0.9**: Excellent! Ready for production\n",
    "- **0.9+**: Outstanding! Professional-grade accuracy\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Download the model** (`block_detector_TRAINED.pt`) from Google Drive\n",
    "2. **Add to your project:**\n",
    "   ```bash\n",
    "   # On your computer:\n",
    "   Move-Item \"C:\\Users\\HP PRO\\Downloads\\block_detector_TRAINED.pt\" \"c:\\Users\\HP PRO\\Desktop\\sam_blocks_inventory\\models\\block_detector.pt\"\n",
    "   ```\n",
    "3. **Deploy to Railway** (commit and push)\n",
    "4. **Test on live site!**\n",
    "\n",
    "## üìö For Your Defense\n",
    "\n",
    "**\"How did you train the AI?\"**\n",
    "> \"I used transfer learning with YOLOv8, starting from a model pretrained on 1.2M images. I fine-tuned it on my custom dataset of [X] labeled block images using Google Colab's free GPU. Training took 50 epochs with an 80/20 train-validation split. The model achieved [X]% mAP50 accuracy.\"\n",
    "\n",
    "**\"Why Google Colab?\"**\n",
    "> \"Google Colab provides free GPU access (Tesla T4), which accelerates training 10-50x compared to CPU. It's industry-standard for ML training and eliminates the need for expensive hardware. Training that would take 4+ hours on CPU completed in 15-30 minutes on GPU.\"\n",
    "\n",
    "**\"What is mAP50?\"**\n",
    "> \"Mean Average Precision at 50% IoU (Intersection over Union). It measures how accurately the model detects blocks. A score above 0.7 indicates the model correctly identifies blocks with good bounding box placement in most cases.\"\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Troubleshooting\n",
    "\n",
    "**Out of memory error?**\n",
    "- Reduce batch size: Change `batch=8` to `batch=4` in cell 8\n",
    "\n",
    "**Low accuracy (< 0.5)?**\n",
    "- Label 10-20 more images\n",
    "- Train longer: Change `epochs=50` to `epochs=100`\n",
    "- Use larger model: Change `yolov8n-seg.pt` to `yolov8s-seg.pt`\n",
    "\n",
    "**Runtime disconnected?**\n",
    "- All results are saved to Google Drive\n",
    "- Rerun cells from the top\n",
    "- Training will resume from last checkpoint\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Happy Training!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0229c98",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç TROUBLESHOOTING: 0 Blocks Detected\n",
    "\n",
    "If your model detected 0 blocks, let's diagnose the problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861d88bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic 1: Check what's in your label files\n",
    "print(\"üîç DIAGNOSTIC 1: Inspecting Label Files\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "labels_path = Path('/content/block_dataset/labels')\n",
    "label_files = list(labels_path.glob('*.txt'))\n",
    "\n",
    "if label_files:\n",
    "    # Check first 5 label files\n",
    "    print(f\"\\nüìÑ Found {len(label_files)} label files\")\n",
    "    print(\"\\nSample of first 3 labels:\\n\")\n",
    "    \n",
    "    for i, label_file in enumerate(label_files[:3]):\n",
    "        print(f\"File: {label_file.name}\")\n",
    "        with open(label_file, 'r') as f:\n",
    "            content = f.read().strip()\n",
    "            if content:\n",
    "                lines = content.split('\\n')\n",
    "                print(f\"  Lines: {len(lines)}\")\n",
    "                print(f\"  First line: {lines[0]}\")\n",
    "                \n",
    "                # Parse the line\n",
    "                parts = lines[0].split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = parts[0]\n",
    "                    print(f\"  Class ID: {class_id} (should be 0 for blocks)\")\n",
    "                    if class_id != '0':\n",
    "                        print(f\"  ‚ö†Ô∏è  WARNING: Class ID is '{class_id}', not '0'!\")\n",
    "            else:\n",
    "                print(f\"  ‚ö†Ô∏è  EMPTY FILE!\")\n",
    "        print()\n",
    "    \n",
    "    # Check if all labels use class 0\n",
    "    all_classes = set()\n",
    "    for label_file in label_files:\n",
    "        with open(label_file, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    class_id = line.strip().split()[0]\n",
    "                    all_classes.add(class_id)\n",
    "    \n",
    "    print(f\"üìä All class IDs found in labels: {sorted(all_classes)}\")\n",
    "    if all_classes != {'0'}:\n",
    "        print(\"‚ö†Ô∏è  PROBLEM: Labels contain classes other than '0'!\")\n",
    "        print(\"   Your data.yaml says class 0 = block, but labels have different classes.\")\n",
    "else:\n",
    "    print(\"‚ùå No label files found!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic 2: Visualize what the model learned\n",
    "print(\"\\nüîç DIAGNOSTIC 2: Visualizing Training Data\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from PIL import Image as PILImage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Pick a training image with labels\n",
    "train_images_path = Path('/content/block_dataset/train/images')\n",
    "train_labels_path = Path('/content/block_dataset/train/labels')\n",
    "\n",
    "train_imgs = list(train_images_path.glob('*'))\n",
    "if train_imgs:\n",
    "    sample_img = train_imgs[0]\n",
    "    sample_label = train_labels_path / f\"{sample_img.stem}.txt\"\n",
    "    \n",
    "    print(f\"üì∏ Sample training image: {sample_img.name}\\n\")\n",
    "    \n",
    "    # Load image\n",
    "    img = PILImage.open(sample_img)\n",
    "    img_width, img_height = img.size\n",
    "    \n",
    "    # Load labels\n",
    "    if sample_label.exists():\n",
    "        with open(sample_label, 'r') as f:\n",
    "            labels = [line.strip().split() for line in f if line.strip()]\n",
    "        \n",
    "        print(f\"üìä This image has {len(labels)} labeled object(s)\")\n",
    "        \n",
    "        # Visualize\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "        ax.imshow(img)\n",
    "        \n",
    "        # Draw bounding boxes from labels\n",
    "        for i, label in enumerate(labels):\n",
    "            class_id, x_center, y_center, width, height = map(float, label)\n",
    "            \n",
    "            # Convert normalized coordinates to pixels\n",
    "            x_center_px = x_center * img_width\n",
    "            y_center_px = y_center * img_height\n",
    "            width_px = width * img_width\n",
    "            height_px = height * img_height\n",
    "            \n",
    "            # Calculate top-left corner\n",
    "            x1 = x_center_px - width_px / 2\n",
    "            y1 = y_center_px - height_px / 2\n",
    "            \n",
    "            # Draw rectangle\n",
    "            rect = patches.Rectangle(\n",
    "                (x1, y1), width_px, height_px,\n",
    "                linewidth=3, edgecolor='red', facecolor='none'\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "            # Add label\n",
    "            ax.text(x1, y1-10, f'Class {int(class_id)}', \n",
    "                   color='red', fontsize=12, fontweight='bold',\n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        ax.set_title(f\"Ground Truth Labels: {sample_img.name}\", fontsize=14, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nüí° Questions to ask:\")\n",
    "        print(\"  1. Do the RED boxes match your hollow blocks?\")\n",
    "        print(\"  2. Or do they mark something else (bricks, walls, etc)?\")\n",
    "        print(\"  3. Are the boxes too small/large?\")\n",
    "        print(\"  4. Do they capture the full block or just part of it?\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  No label file found for {sample_img.name}\")\n",
    "else:\n",
    "    print(\"‚ùå No training images found!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9191a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic 3: Test on different confidence thresholds\n",
    "print(\"\\nüîç DIAGNOSTIC 3: Testing Different Confidence Thresholds\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test the same image with lower confidence threshold\n",
    "test_image = list(val_images.glob('*'))[0]\n",
    "print(f\"Testing: {test_image.name}\\n\")\n",
    "\n",
    "# Try different confidence thresholds\n",
    "for conf_threshold in [0.001, 0.01, 0.05, 0.1, 0.25, 0.5]:\n",
    "    results = trained_model(test_image, conf=conf_threshold, verbose=False)\n",
    "    num_detections = len(results[0].boxes)\n",
    "    print(f\"Confidence {conf_threshold:.3f}: {num_detections} detection(s)\")\n",
    "\n",
    "print(\"\\nüí° If you see 0 detections even at 0.001, the model didn't learn!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabbe3c6",
   "metadata": {},
   "source": [
    "## üîß SOLUTIONS Based on Diagnosis\n",
    "\n",
    "Run the diagnostic cells above, then choose your solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e157d8a",
   "metadata": {},
   "source": [
    "### Problem 1: Wrong Class IDs in Labels\n",
    "\n",
    "**Symptom:** Diagnostic 1 shows class IDs other than '0'\n",
    "\n",
    "**Cause:** Your labeling tool exported different class numbers\n",
    "\n",
    "**Solution:** Fix all labels to use class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d1f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION 1: Fix class IDs in all label files\n",
    "# Run this ONLY if Diagnostic 1 showed wrong class IDs\n",
    "\n",
    "import os\n",
    "\n",
    "labels_dir = Path('/content/drive/MyDrive/block_dataset/labels')\n",
    "fixed_count = 0\n",
    "\n",
    "print(\"üîß Fixing class IDs in label files...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for label_file in labels_dir.glob('*.txt'):\n",
    "    with open(label_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    new_lines = []\n",
    "    modified = False\n",
    "    \n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                old_class = parts[0]\n",
    "                if old_class != '0':\n",
    "                    # Change class ID to 0\n",
    "                    parts[0] = '0'\n",
    "                    modified = True\n",
    "                new_lines.append(' '.join(parts) + '\\n')\n",
    "            else:\n",
    "                new_lines.append(line)\n",
    "    \n",
    "    if modified:\n",
    "        with open(label_file, 'w') as f:\n",
    "            f.writelines(new_lines)\n",
    "        fixed_count += 1\n",
    "\n",
    "print(f\"‚úÖ Fixed {fixed_count} label files\")\n",
    "print(f\"üìä Total labels processed: {len(list(labels_dir.glob('*.txt')))}\")\n",
    "print(\"\\nüîÑ Now RE-RUN cells 5-8 to retrain with fixed labels!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c91cf3a",
   "metadata": {},
   "source": [
    "### Problem 2: Labels Mark Wrong Objects\n",
    "\n",
    "**Symptom:** Diagnostic 2 shows boxes around bricks/walls, not hollow blocks\n",
    "\n",
    "**Cause:** Your labeling tool was trained on wrong images OR you labeled wrong objects\n",
    "\n",
    "**Solution:** You need to re-label your images with the correct objects (hollow blocks only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f7ab38",
   "metadata": {},
   "source": [
    "**How to fix:**\n",
    "\n",
    "1. **Use LabelImg or Roboflow** to manually label hollow blocks:\n",
    "   - Download LabelImg: https://github.com/HumanSignal/labelImg\n",
    "   - Or use Roboflow: https://roboflow.com/ (easier, web-based)\n",
    "\n",
    "2. **What to label:**\n",
    "   - ‚úÖ Hollow concrete blocks (interlocks)\n",
    "   - ‚ùå NOT bricks, walls, or other objects\n",
    "\n",
    "3. **Labeling tips:**\n",
    "   - Draw tight boxes around each block\n",
    "   - Include the full block (all edges)\n",
    "   - Label ALL blocks in each image (don't skip any)\n",
    "   - Class name: \"block\" or class ID: 0\n",
    "\n",
    "4. **Export format:**\n",
    "   - YOLO format (class x_center y_center width height)\n",
    "   - All values normalized 0-1\n",
    "\n",
    "5. **Upload corrected labels** back to Google Drive and re-train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48180019",
   "metadata": {},
   "source": [
    "### Problem 3: Not Enough Training Data\n",
    "\n",
    "**Symptom:** Model trained but accuracy is very low (mAP50 < 0.3)\n",
    "\n",
    "**Cause:** 39 images is borderline - needs more examples\n",
    "\n",
    "**Solution:** Add more labeled images (aim for 50-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c93ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION 3: Data augmentation (if you can't get more images)\n",
    "# This artificially increases dataset by creating variations\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"üîß Re-training with MORE augmentation...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Retrain with aggressive augmentation\n",
    "model_aug = YOLO('yolov8n-seg.pt')\n",
    "\n",
    "results = model_aug.train(\n",
    "    data=str(dataset_path / 'data.yaml'),\n",
    "    epochs=100,             # More epochs!\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    patience=20,            # More patience\n",
    "    save=True,\n",
    "    project=save_dir,\n",
    "    name='sam_blocks_v2_augmented',\n",
    "    exist_ok=True,\n",
    "    \n",
    "    # AGGRESSIVE AUGMENTATION\n",
    "    hsv_h=0.05,            # Hue variation\n",
    "    hsv_s=0.7,             # Saturation\n",
    "    hsv_v=0.4,             # Brightness\n",
    "    degrees=15,             # Rotation\n",
    "    translate=0.2,          # Shifting\n",
    "    scale=0.5,              # Zooming\n",
    "    shear=10,               # Shearing\n",
    "    perspective=0.001,      # Perspective transform\n",
    "    flipud=0.5,             # Vertical flip\n",
    "    fliplr=0.5,             # Horizontal flip\n",
    "    mosaic=1.0,             # Mosaic augmentation\n",
    "    mixup=0.1,              # Mixup augmentation\n",
    "    \n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete with augmentation!\")\n",
    "print(\"üîÑ Now run cells 9-11 again to test this new model\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
